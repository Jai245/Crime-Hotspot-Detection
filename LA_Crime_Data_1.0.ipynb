{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\rosel\\Downloads\\New folder\\LA Crime\\LA_Crime_Data_from_2020_to_2024.csv\", chunksize=100000)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "corr_matrix = df.select_dtypes(include=[\"number\"]).corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing few columns due to multicollinearity\n",
    "df.drop(columns=['DR_NO','Rpt Dist No'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_dates = df[pd.to_datetime(df['DATE OCC'], errors='coerce').isna()]\n",
    "print(invalid_dates[['DATE OCC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically infers the format and handles bad data safely\n",
    "df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Now safely extract the weekday name\n",
    "df['weekday'] = df['DATE OCC'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure TIME OCC is zero-padded\n",
    "df['TIME OCC'] = df['TIME OCC'].astype(str).str.zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hour and minute\n",
    "df['Hour'] = df['TIME OCC'].str[:2].astype(int)\n",
    "df['Minute'] = df['TIME OCC'].str[2:].astype(int)\n",
    "\n",
    "# Creating \"Time of Day\" buckets\n",
    "def time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df['TimeOfDay'] = df['Hour'].apply(time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearMonth'] = df['DATE OCC'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Drop rows with missing coordinates\n",
    "df_clean = df.dropna(subset=['LAT', 'LON'])\n",
    "\n",
    "# Use KMeans to group into zones (e.g., 10)\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "df_clean['Zone'] = kmeans.fit_predict(df_clean[['LAT', 'LON']])\n",
    "\n",
    "# Merge back if needed\n",
    "df['Zone'] = df_clean['Zone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "K = range(2, 20)\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(df_clean[['LAT', 'LON']])\n",
    "    inertias.append(model.inertia_)\n",
    "\n",
    "plt.plot(K, inertias, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal Zone Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "optimal_k = 5\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "df['Zone'] = kmeans.fit_predict(df[['LAT', 'LON']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LA bounding box (roughly)\n",
    "df = df[(df['LAT'] > 33) & (df['LAT'] < 35) & (df['LON'] < -117) & (df['LON'] > -119)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['LON'], df['LAT'], c=df['Zone'], cmap='tab10', alpha=0.5)\n",
    "plt.title(\"Crime Zones Based on Clustering\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by Location to count how many crimes happened at or near the same location\n",
    "hotspot_counts = df.groupby(['LAT', 'LON']).size().reset_index(name='crime_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Back to Original Data\n",
    "df = df.merge(hotspot_counts, on=['LAT', 'LON'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['crime_count'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = df['crime_count'].quantile(0.90)\n",
    "df['Hotspot'] = df['crime_count'].apply(lambda x: 'Hotspot' if x >= threshold else 'Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'Hotspot': 'red', 'Normal': 'blue'}\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in df['Hotspot'].unique():\n",
    "    subset = df[df['Hotspot'] == label]\n",
    "    plt.scatter(subset['LON'], subset['LAT'], \n",
    "                c=colors[label], label=label, s=10, alpha=0.6)\n",
    "\n",
    "plt.title(\"Crime Hotspots in the City\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After clustering\n",
    "df['ClusterCrimeCount'] = df.groupby('Zone')['Zone'].transform('count')\n",
    "threshold = df['ClusterCrimeCount'].quantile(0.9)\n",
    "\n",
    "# Labeling Hotspots\n",
    "df['Hotspot'] = df['ClusterCrimeCount'].apply(lambda x: 'Hotspot' if x >= threshold else 'Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import FastMarkerCluster\n",
    "\n",
    "# Define the map center\n",
    "map_center = [df['LAT'].mean(), df['LON'].mean()]\n",
    "\n",
    "# Create the base map\n",
    "m = folium.Map(location=map_center, zoom_start=11)\n",
    "\n",
    "# Prepare data for FastMarkerCluster\n",
    "locations = df[['LAT', 'LON']].values.tolist()\n",
    "FastMarkerCluster(data=locations).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotspot_trend = df.groupby(['Zone', 'YearMonth']).size().reset_index(name='CrimeCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_crimes = df[df['Hotspot'] == 'Hotspot']['Crm Cd Desc'].value_counts().head(10)\n",
    "print(top_crimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Encode target\n",
    "df['Hotspot'] = (df['crime_count'] > 50).astype(int)\n",
    "\n",
    "# Drop rows where target is NaN\n",
    "df_encoded = df.dropna(subset=['Hotspot'])\n",
    "\n",
    "# Assuming 'DATE OCC' is a datetime column\n",
    "df_encoded['DATE_OCC_year'] = df_encoded['DATE OCC'].dt.year\n",
    "df_encoded['DATE_OCC_month'] = df_encoded['DATE OCC'].dt.month\n",
    "df_encoded['DATE_OCC_day'] = df_encoded['DATE OCC'].dt.day\n",
    "\n",
    "# Convert categorical columns to category dtype\n",
    "categorical_columns = ['Vict Sex', 'Vict Descent', 'Status', 'Zone', 'Cross Street', 'weekday', 'TimeOfDay', 'YearMonth']\n",
    "for col in categorical_columns:\n",
    "    df_encoded[col] = df_encoded[col].astype('category')\n",
    "\n",
    "# Now drop any columns you don't need\n",
    "X = df_encoded.drop(columns=[\n",
    "    'Hotspot', 'crime_count', 'ClusterCrimeCount', \n",
    "    'Date Rptd', 'AREA NAME', 'Crm Cd Desc', 'Mocodes', \n",
    "    'Premis Desc', 'Weapon Desc', 'Status Desc', 'DATE OCC'\n",
    "])\n",
    "y = df_encoded['Hotspot']\n",
    "\n",
    "# Convert 'YearMonth' from period to category\n",
    "if 'YearMonth' in X.columns:\n",
    "    X['YearMonth'] = X['YearMonth'].astype(str).astype('category')\n",
    "\n",
    "# Convert all object columns to category\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)               # original size\n",
    "print(df['Hotspot'].value_counts(dropna=False))  # see what's in the 'Hotspot' column\n",
    "print(df_encoded.shape)       # shape after dropping NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Optuna objective\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'auto',\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**param, enable_categorical=True)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Show results\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_params = study.best_params\n",
    "best_model = xgb.XGBClassifier(**best_params, enable_categorical=True)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_valid)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_valid, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Use the underlying booster model\n",
    "booster = best_model.get_booster()\n",
    "\n",
    "# Prepare validation data for booster\n",
    "dvalid = xgb.DMatrix(X_valid, enable_categorical=True)\n",
    "\n",
    "# Predict SHAP values\n",
    "shap_values = booster.predict(dvalid, pred_contribs=True)\n",
    "\n",
    "# visualize one example\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values_plot = explainer.shap_values(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create force plot for the first prediction\n",
    "force_html_path = \"assets/xgb_shap_force.html\"\n",
    "os.makedirs(\"assets\", exist_ok=True)\n",
    "\n",
    "# Generate force plot HTML\n",
    "shap.initjs()\n",
    "force_plot = shap.force_plot(\n",
    "    base_value=explainer.expected_value,\n",
    "    shap_values=shap_values[0][:-1],  # Remove last element\n",
    "    features=X_valid.iloc[0],\n",
    "    matplotlib=False\n",
    ")\n",
    "\n",
    "shap.save_html(force_html_path, force_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary DataFrame\n",
    "shap_df = pd.DataFrame(shap_values[:, :-1], columns=X_valid.columns)\n",
    "shap_importance = shap_df.abs().mean().sort_values(ascending=False).reset_index()\n",
    "shap_importance.columns = ['Feature', 'Mean SHAP Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feature = shap_importance.iloc[0]['Feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns.tolist()\n",
    "print(\"Loaded feature_columns:\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save KMeans model\n",
    "joblib.dump(kmeans, \"kmeans_zone.pkl\")\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, \"crime_model.pkl\")\n",
    "\n",
    "# Save the SHAP explainer\n",
    "joblib.dump(explainer, \"shap_explainer.pkl\")\n",
    "\n",
    "# Save the feature names\n",
    "joblib.dump(X_valid.columns.tolist(), \"feature_columns.pkl\")\n",
    "\n",
    "# Save the SHAP values\n",
    "joblib.dump(shap_values, \"shap_values.pkl\")\n",
    "\n",
    "print(\"Model, explainer, and feature names saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the KMeans model\n",
    "kmeans = joblib.load(\"kmeans_zone.pkl\")\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load(\"crime_model.pkl\")\n",
    "\n",
    "# Load the SHAP explainer\n",
    "explainer = joblib.load(\"shap_explainer.pkl\")\n",
    "\n",
    "# Load the feature names\n",
    "feature_columns = joblib.load(\"feature_columns.pkl\")\n",
    "\n",
    "shap_values = joblib.load(\"shap_values.pkl\")\n",
    "\n",
    "# Print out feature names\n",
    "print(\"Loaded feature_columns:\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import html, dcc\n",
    "from dash.dependencies import Input, Output\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "import os\n",
    "\n",
    "# Data update function (runs daily)\n",
    "def update_data():\n",
    "    print(\"Updating crime data...\")\n",
    "\n",
    "    # Load raw data\n",
    "    df = pd.read_csv(r\"C:\\Users\\rosel\\Downloads\\New folder\\LA Crime\\raw_crime_data.csv\")\n",
    "\n",
    "    # Initial row count\n",
    "    initial_rows = len(df)\n",
    "    print(f\"Loaded {initial_rows} rows from raw CSV.\")\n",
    "\n",
    "    # Parse dates\n",
    "    df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], errors='coerce')\n",
    "    print(f\"Invalid DATE OCC values: {df['DATE OCC'].isna().sum()}\")\n",
    "    \n",
    "    # Report invalid dates\n",
    "    invalid_dates = df['DATE OCC'].isna().sum()\n",
    "    print(f\"Invalid DATE OCC values: {invalid_dates}\")\n",
    "\n",
    "    # Try converting LAT/LON and report issues\n",
    "    df['LAT'] = pd.to_numeric(df['LAT'], errors='coerce')\n",
    "    df['LON'] = pd.to_numeric(df['LON'], errors='coerce')\n",
    "\n",
    "    invalid_coords = df[['LAT', 'LON']].isna().any(axis=1).sum()\n",
    "    print(f\"Rows with invalid LAT/LON: {invalid_coords}\")\n",
    "\n",
    "    # Drop rows with bad values\n",
    "    df = df.dropna(subset=['DATE OCC', 'LAT', 'LON'])\n",
    "\n",
    "    # Add time features\n",
    "    df['TimeOfDay'] = df['DATE OCC'].dt.to_period('M').astype(str)\n",
    "    df['weekday'] = df['DATE OCC'].dt.day_name()\n",
    "\n",
    "    final_rows = len(df)\n",
    "    print(f\"Rows after cleaning: {final_rows}\")\n",
    "\n",
    "    # Save debug version before writing final CSV\n",
    "    df.to_csv('latest_crime_data_debug.csv', index=False)  # <-- temporary debugging file\n",
    "    df.to_csv('latest_crime_data.csv', index=False)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"⚠️ WARNING: All rows were dropped after cleaning. Check raw data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule daily updates\n",
    "update_data()\n",
    "scheduler = BackgroundScheduler()\n",
    "scheduler.add_job(update_data, 'interval', days=1)\n",
    "scheduler.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "df = pd.read_csv('latest_crime_data.csv')\n",
    "df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], format='%m/%d/%Y', errors='coerce')\n",
    "df['weekday'] = df['DATE OCC'].dt.day_name()\n",
    "df['TimeOfDay'] = df['DATE OCC'].dt.to_period('M').astype(str)\n",
    "df = df.dropna(subset=['LAT', 'LON'])\n",
    "df['LAT'] = df['LAT'].astype(float)\n",
    "df['LON'] = df['LON'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Ensure 'DATE OCC' is datetime\n",
    "df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], errors='coerce')\n",
    "\n",
    "# Clean and convert 'TIME OCC'\n",
    "df['TIME OCC'] = pd.to_numeric(df['TIME OCC'], errors='coerce')  # Converts to float, invalid to NaN\n",
    "df = df.dropna(subset=['TIME OCC'])  # Drop rows where TIME OCC is invalid\n",
    "df['TIME OCC'] = df['TIME OCC'].astype(int)\n",
    "\n",
    "# Extract hour/minute and create TimeOfDay label\n",
    "df['Minute'] = df['TIME OCC'] % 100\n",
    "df['Hour'] = df['TIME OCC'] // 100\n",
    "df['TimeOfDay'] = pd.cut(\n",
    "    df['Hour'],\n",
    "    bins=[-1, 5, 11, 17, 21, 24],\n",
    "    labels=['Night', 'Morning', 'Afternoon', 'Evening', 'Night'],\n",
    "    ordered=False,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Extract date parts\n",
    "df['YearMonth'] = df['DATE OCC'].dt.to_period('M').astype(str)\n",
    "df['DATE_OCC_year'] = df['DATE OCC'].dt.year\n",
    "df['DATE_OCC_month'] = df['DATE OCC'].dt.month\n",
    "df['DATE_OCC_day'] = df['DATE OCC'].dt.day\n",
    "df['weekday'] = df['DATE OCC'].dt.day_name()\n",
    "\n",
    "# KMeans clustering on valid coordinates\n",
    "coords = df[['LAT', 'LON']].dropna()\n",
    "\n",
    "if not coords.empty:\n",
    "    kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "    df.loc[coords.index, 'Zone'] = kmeans.fit_predict(coords)\n",
    "else:\n",
    "    print(\"No data available for clustering.\")\n",
    "    df['Zone'] = np.nan  # Safe fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and engineer features\n",
    "df = pd.read_csv('latest_crime_data.csv')\n",
    "\n",
    "# Convert DATE OCC to datetime\n",
    "df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], errors='coerce')\n",
    "\n",
    "# Optional clean-up or checks\n",
    "df = df.dropna(subset=['DATE OCC'])\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "server = app.server\n",
    "\n",
    "# Your layout and callbacks (example layout)\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Crime Hotspots Dashboard\", style={'textAlign': 'center'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(\"Crime Type:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='crime-type-filter',\n",
    "                options=[{'label': ct, 'value': ct} for ct in sorted(df['Crm Cd Desc'].dropna().unique())],\n",
    "                placeholder=\"All types\",\n",
    "                multi=True\n",
    "            ),\n",
    "        ], style={'width': '24%', 'display': 'inline-block', 'marginRight': '1%'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Area:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='area-filter',\n",
    "                options=[{'label': a, 'value': a} for a in sorted(df['AREA'].dropna().unique())],\n",
    "                placeholder=\"All areas\"\n",
    "            ),\n",
    "        ], style={'width': '24%', 'display': 'inline-block', 'marginRight': '1%'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Weekday:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='weekday-filter',\n",
    "                options=[{'label': day, 'value': day} for day in df['weekday'].unique()],\n",
    "                placeholder=\"All days\"\n",
    "            ),\n",
    "        ], style={'width': '24%', 'display': 'inline-block', 'marginRight': '1%'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Date Range:\"),\n",
    "            dcc.DatePickerRange(\n",
    "                id='date-range-filter',\n",
    "                min_date_allowed=df['DATE OCC'].min().date(),\n",
    "                max_date_allowed=df['DATE OCC'].max().date(),\n",
    "                start_date=df['DATE OCC'].min().date(),\n",
    "                end_date=df['DATE OCC'].max().date(),\n",
    "            ),\n",
    "        ], style={'width': '24%', 'display': 'inline-block'}),\n",
    "    ], style={'paddingBottom': '20px'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(\"Time of Day:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='timeofday-filter',\n",
    "                options=[{'label': t, 'value': t} for t in df['TimeOfDay'].unique()],\n",
    "                placeholder=\"Select time of day\",\n",
    "                searchable=True\n",
    "            ),\n",
    "        ], style={'width': '32%', 'display': 'inline-block', 'marginRight': '1%'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Victim Gender:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='vict-sex-filter',\n",
    "                options=[{'label': sex, 'value': sex} for sex in df['Vict Sex'].dropna().unique()],\n",
    "                placeholder=\"Victim sex\",\n",
    "                searchable=True\n",
    "            ),\n",
    "        ], style={'width': '32%', 'display': 'inline-block', 'marginRight': '1%'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Victim Age Range:\"),\n",
    "            dcc.RangeSlider(\n",
    "                id='vict-age-filter',\n",
    "                min=df['Vict Age'].min(),\n",
    "                max=df['Vict Age'].max(),\n",
    "                step=1,\n",
    "                marks=None,\n",
    "                tooltip={\"placement\": \"bottom\", \"always_visible\": True},\n",
    "                value=[df['Vict Age'].min(), df['Vict Age'].max()]\n",
    "            )\n",
    "        ], style={'width': '24%', 'display': 'inline-block'})\n",
    "    ], style={'paddingBottom': '20px'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.Label(\"Status:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='status-filter',\n",
    "            options=[{'label': s, 'value': s} for s in df['Status Desc'].dropna().unique()],\n",
    "            placeholder=\"Select status\",\n",
    "            searchable=True\n",
    "        )\n",
    "    ], style={'width': '24%', 'display': 'inline-block', 'paddingBottom': '20px'}),\n",
    "\n",
    "    html.Div(id='active-filters-display'),\n",
    "    html.Iframe(id='map-graph', width='100%', height='600'),\n",
    "\n",
    "    \n",
    "    html.Div([\n",
    "        html.H3(\"SHAP Summary Plot\"),\n",
    "        html.Img(src=\"/assets/shap_summary.png\", style={'width': '100%', 'height': 'auto'}),\n",
    "    ], style={'marginTop': '40px'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.H2(\"XGBoost SHAP Feature Importance\", style={'textAlign': 'center'}),\n",
    "\n",
    "        dcc.Graph(\n",
    "            id='xgb-shap-bar-plot',\n",
    "            figure=px.bar(\n",
    "                shap_importance.head(20),\n",
    "                x='Mean SHAP Value',\n",
    "                y='Feature',\n",
    "                orientation='h',\n",
    "                title=\"Top 20 SHAP Features (XGBoost)\"\n",
    "            )\n",
    "        ),\n",
    "\n",
    "    html.Div([\n",
    "        html.Label(\"Select Feature for XGBoost SHAP Dependence Plot:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='xgb-shap-feature-dropdown',\n",
    "            options=[{'label': col, 'value': col} for col in X_valid.columns],\n",
    "            value=top_feature\n",
    "        ),\n",
    "        dcc.Graph(id='xgb-shap-dependence-plot')\n",
    "    ], style={'marginTop': '30px'})\n",
    "    ], style={'marginTop': '60px'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.H3(\"XGBoost SHAP Force Plot (First Instance)\"),\n",
    "        html.Iframe(src=\"/assets/xgb_shap_force.html\", width=\"100%\", height=\"400\")\n",
    "    ], style={'marginTop': '40px'}),\n",
    "    \n",
    "    dcc.Graph(id='shap-bar-plot')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Input, Output\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "@app.callback(\n",
    "    Output('map-graph', 'srcDoc'),\n",
    "    Input('crime-type-filter', 'value'),\n",
    "    Input('area-filter', 'value'),\n",
    "    Input('weekday-filter', 'value'),\n",
    "    Input('date-range-filter', 'start_date'),\n",
    "    Input('date-range-filter', 'end_date'),\n",
    "    Input('timeofday-filter', 'value'),\n",
    "    Input('vict-sex-filter', 'value'),\n",
    "    Input('vict-age-filter', 'value'),\n",
    "    Input('status-filter', 'value')\n",
    ")\n",
    "    \n",
    "def update_map(crime_types, area, weekday, start_date, end_date, time_of_day, vict_sex, age_range, status):\n",
    "    # Start with full dataframe\n",
    "    filtered_df = df.copy()\n",
    "\n",
    "    # Apply filters\n",
    "    if crime_types:\n",
    "        filtered_df = filtered_df[filtered_df['Crm Cd Desc'].isin(crime_types)]\n",
    "\n",
    "    if area:\n",
    "        filtered_df = filtered_df[filtered_df['AREA'] == area]\n",
    "\n",
    "    if weekday:\n",
    "        filtered_df = filtered_df[filtered_df['weekday'] == weekday]\n",
    "\n",
    "    if start_date and end_date:\n",
    "        filtered_df = filtered_df[(filtered_df['DATE OCC'] >= start_date) & (filtered_df['DATE OCC'] <= end_date)]\n",
    "\n",
    "    if time_of_day:\n",
    "        filtered_df = filtered_df[filtered_df['TimeOfDay'] == time_of_day]\n",
    "\n",
    "    if vict_sex:\n",
    "        filtered_df = filtered_df[filtered_df['Vict Sex'] == vict_sex]\n",
    "\n",
    "    if age_range:\n",
    "        min_age, max_age = age_range\n",
    "        filtered_df = filtered_df[(filtered_df['Vict Age'] >= min_age) & (filtered_df['Vict Age'] <= max_age)]\n",
    "        \n",
    "    if status:\n",
    "        filtered_df = filtered_df[filtered_df['Status Desc'] == status]\n",
    "\n",
    "    active_filters = html.Ul([\n",
    "        html.Li(f\"Crime Types: {', '.join(crime_types) if crime_types else 'All'}\"),\n",
    "        html.Li(f\"Area: {area if area else 'All'}\"),\n",
    "        html.Li(f\"Weekday: {weekday if weekday else 'All'}\"),\n",
    "        html.Li(f\"Date Range: {start_date} to {end_date}\"),\n",
    "        html.Li(f\"Time of Day: {time_of_day if time_of_day else 'All'}\"),\n",
    "        html.Li(f\"Victim Sex: {vict_sex if vict_sex else 'All'}\"),\n",
    "        html.Li(f\"Victim Age: {min_age} to {max_age}\"),\n",
    "        html.Li(f\"Status: {status if status else 'All'}\")\n",
    "    ])\n",
    "\n",
    "# Create map with Folium\n",
    "    \n",
    "\n",
    "    if not filtered_df.empty:\n",
    "        m = folium.Map(\n",
    "        location=[filtered_df['LAT'].mean(), filtered_df['LON'].mean()],\n",
    "        zoom_start=11,\n",
    "        tiles='CartoDB positron')  # or 'Stamen Toner', 'OpenStreetMap'\n",
    "        marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "        for _, row in filtered_df.iterrows():\n",
    "            popup_text = f\"\"\"\n",
    "            <b>Crime:</b> {row['Crm Cd Desc']}<br>\n",
    "            <b>Date:</b> {row['DATE OCC']}<br>\n",
    "            <b>Victim Sex:</b> {row['Vict Sex']}<br>\n",
    "            <b>Victim Age:</b> {row['Vict Age']}<br>\n",
    "            <b>Status:</b> {row['Status']}\n",
    "            \"\"\"\n",
    "            folium.Marker(\n",
    "                location=[row['LAT'], row['LON']],\n",
    "                popup=popup_text\n",
    "            ).add_to(marker_cluster)\n",
    "\n",
    "        return m.get_root().render()\n",
    "    else:\n",
    "        return \"<h3>No data available for selected filters.</h3>\"\n",
    "\n",
    "@app.callback(\n",
    "    Output('xgb-shap-dependence-plot', 'figure'),\n",
    "    Input('xgb-shap-feature-dropdown', 'value')\n",
    ")\n",
    "def update_xgb_dependence_plot(selected_feature):\n",
    "    fig = px.scatter(\n",
    "        x=X_valid[selected_feature],\n",
    "        y=shap_df[selected_feature],\n",
    "        labels={'x': selected_feature, 'y': 'SHAP Value'},\n",
    "        title=f\"SHAP Dependence Plot for {selected_feature} (XGBoost)\"\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('shap-bar-plot', 'figure'),\n",
    "    Input('crime-type-filter', 'value'),\n",
    "    Input('area-filter', 'value'),\n",
    "    Input('weekday-filter', 'value'),\n",
    "    Input('status-filter', 'value'),\n",
    "    Input('vict-sex-filter', 'value'),\n",
    "    Input('timeofday-filter', 'value'),\n",
    "    Input('vict-age-filter', 'value'),\n",
    "    Input('date-range-filter', 'start_date'),\n",
    "    Input('date-range-filter', 'end_date'),\n",
    ")\n",
    "def update_shap_plot(crime_type, area, weekday, status, gender, time_of_day, age_range, start_date, end_date):\n",
    "    filtered_df = df.copy()\n",
    "\n",
    "    # Ensure datetime\n",
    "    filtered_df['DATE OCC'] = pd.to_datetime(filtered_df['DATE OCC'], errors='coerce')\n",
    "\n",
    "    # Apply filters\n",
    "    if crime_type:\n",
    "        filtered_df = filtered_df[filtered_df['Crm Cd Desc'].isin(crime_type)]\n",
    "    if area:\n",
    "        filtered_df = filtered_df[filtered_df['AREA'] == area]\n",
    "    if weekday:\n",
    "        filtered_df = filtered_df[filtered_df['weekday'] == weekday]\n",
    "    if status:\n",
    "        filtered_df = filtered_df[filtered_df['Status Desc'] == status]\n",
    "    if gender:\n",
    "        filtered_df = filtered_df[filtered_df['Vict Sex'] == gender]\n",
    "    if time_of_day:\n",
    "        filtered_df = filtered_df[filtered_df['TimeOfDay'] == time_of_day]\n",
    "    if age_range and len(age_range) == 2:\n",
    "        filtered_df = filtered_df[(filtered_df['Vict Age'] >= age_range[0]) & (filtered_df['Vict Age'] <= age_range[1])]\n",
    "    if start_date and end_date:\n",
    "        filtered_df = filtered_df[(filtered_df['DATE OCC'] >= start_date) & (filtered_df['DATE OCC'] <= end_date)]\n",
    "\n",
    "    # Create needed columns if not present\n",
    "    if 'Hour' not in filtered_df:\n",
    "        filtered_df['Hour'] = filtered_df['TIME OCC'] // 100\n",
    "        filtered_df['Minute'] = filtered_df['TIME OCC'] % 100\n",
    "    if 'YearMonth' not in filtered_df:\n",
    "        filtered_df['YearMonth'] = filtered_df['DATE OCC'].dt.to_period('M').astype(str)\n",
    "    if 'DATE_OCC_year' not in filtered_df:\n",
    "        filtered_df['DATE_OCC_year'] = filtered_df['DATE OCC'].dt.year\n",
    "    if 'DATE_OCC_month' not in filtered_df:\n",
    "        filtered_df['DATE_OCC_month'] = filtered_df['DATE OCC'].dt.month\n",
    "    if 'DATE_OCC_day' not in filtered_df:\n",
    "        filtered_df['DATE_OCC_day'] = filtered_df['DATE OCC'].dt.day\n",
    "    if 'Zone' not in filtered_df:\n",
    "        filtered_df['Zone'] = filtered_df['AREA']\n",
    "\n",
    "    X_filtered = filtered_df[feature_columns]\n",
    "\n",
    "    if X_filtered.empty:\n",
    "        fig = px.bar(title=\"No data available after applying filters.\")\n",
    "        fig.update_layout(title_x=0.5)\n",
    "        return fig\n",
    "\n",
    "    # PREPROCESS to fix dtype and NaNs\n",
    "    X_filtered = X_filtered.fillna(-999)  # You can also consider other fill methods\n",
    "    for col in X_filtered.select_dtypes(include='object').columns:\n",
    "        X_filtered[col] = X_filtered[col].astype('category').cat.codes\n",
    "\n",
    "    dfilter = xgb.DMatrix(X_filtered)\n",
    "    shap_values = booster.predict(dfilter, pred_contribs=True)\n",
    "    \n",
    "    shap_df = pd.DataFrame(shap_values, columns=list(X_filtered.columns) + ['bias'])\n",
    "    shap_df.drop(columns='bias', inplace=True)\n",
    "\n",
    "    shap_importance = shap_df.abs().mean().sort_values(ascending=False).reset_index()\n",
    "    shap_importance.columns = ['Feature', 'Mean SHAP Value']\n",
    "\n",
    "    fig = px.bar(\n",
    "        shap_importance.head(20),\n",
    "        x='Mean SHAP Value',\n",
    "        y='Feature',\n",
    "        orientation='h',\n",
    "        title='Top SHAP Features for Filtered Data'\n",
    "    )\n",
    "    fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
    "    fig.update_yaxes(autorange='reversed')\n",
    "    fig.update_layout(title_x=0.5)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
